{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LAPKT stands for the L ightweight A utomated P lanning Tool K i T . It aims to make your life easier if your purpose is to create, use or extend basic to advanced Automated Planners. It's an open-source Toolkit written in C++ and Python with simple interfaces that give you complete flexibility by decoupling parsers from problem representations and algorithms. It has been succesfully used in embedded systems, webservices, compilations, replanning and contains some of the high-performance planners from the last International Planning Competition 2014. Overview Link LAPKT separates search engines from the data structures used to represent planning tasks. This second component receives the name of 'interface' since it is indeed the interface that provides the search model to be solved. At the moment of writing this, the following interfaces are offered: agnostic : this interface does not depend on a particular planning language, so it is easy to wrap PDDL parsers, separating parsing representation of planning tasks from a representation optimized for off-line planning. This interface should also make easy to integrate STRIPS planners into applications by suitably defining planning tasks programatically. ff : this interface wraps FF parsing components to obtain agnostic looking tasks. fd : this interface wraps FD parsing components to obtain agnostic looking tasks. Future interfaces planned are: VAL : this interface wraps VAL parser, which supports parsing of PDDL+ features. SAS+ : this interface is meant to support SAS representations natively. Since there is no SAS-based planning language, this will probably be useful to integrate planners into applications that are able to define SAS planning tasks programatically. Tarski : this interface will be used to parse, or build STIPS and more expressive models. Search engine components are meant to be modular, allowing users of LAPKT to assemble and combine features of different search engines to come up with customized search strategies, within reason and without sacrificing (much) efficiency. In order to do so, LAPKT makes heavy use of C++ templates and the Static Strategy design pattern. News! Link 1M solver calls @ planning.domains Link One of our planners, siw-then-bfs has reached over 1M calls in the remote solver handling the calls in the editor.planning.domains May 22, 2020 Sparkle Planning Challenge 2019 Link The Sparkle Planning Challenge automatically combines all participating planners into a state-of-the-art planning selector, and assesses the contribution of each participating planner to the performance of that planning selector. Results and Slides WINNER: PROBE Link RUNNER-UP: DUAL-BFWS Link The planners that got the 1st and 2nd positions were PROBE (based on an early version of LAPKT) and DUAL-BFWS . International Planning Competition (IPC) 2018 Link Results and scores overview WINNER of the Agile Track Link BFWS-preference corresponds to BFWS planner using option --BFWS-f5 RUNNER-UP of the Satisficing Track Link DUAL-BFWS corresponds to BFWS planner using option --DUAL-BFWS For more information about submitted BFWS planners, read this summary width-ipc-paper IPC 2014 Agile track Link Once we fixed the bug on the submission of IPC'8 (International Planning Competition 2014), we were computing $h^2$ but not using it, our planners BFS_f, DFS+, and SIW+ are the fastest in the AGILE track (minimize CPU time) compared to the last winner, according to our experiments using the benchmarks from the competition. Contact & Contributing Link We welcome anybody in the planning community to contribute into LAPKT, either by just using it or by submitting code implementing stuff they feel should be in an \\\"Automated Planning Toolkit\\\". We only request two things from you. First, to abide to the terms and conditions of the Apache License, Version 2.0, January 2004 (http://www.apache.org/licenses/). Second, to drop a note on us telling about what you plan to add or what you think should be changed. You can contribute to LAPKT by submitting code or discussing issues @ github . General questions: Miquel Ramirez and Nir Lipovetzky \\<firstname.surname\\@unimelb.edu.au> Citing LAPKT Link You can use cite LAPKT in your publications like this: @misc{lapkt, title = {{ Lightweight Automated Planning ToolKiT }} , author = {Miquel Ramirez and Nir Lipovetzky and Christian Muise}, howpublished = {\\url{http://lapkt.org/}}, year = {2015}, note = {Accessed: 2020} }","title":"Home"},{"location":"#overview","text":"LAPKT separates search engines from the data structures used to represent planning tasks. This second component receives the name of 'interface' since it is indeed the interface that provides the search model to be solved. At the moment of writing this, the following interfaces are offered: agnostic : this interface does not depend on a particular planning language, so it is easy to wrap PDDL parsers, separating parsing representation of planning tasks from a representation optimized for off-line planning. This interface should also make easy to integrate STRIPS planners into applications by suitably defining planning tasks programatically. ff : this interface wraps FF parsing components to obtain agnostic looking tasks. fd : this interface wraps FD parsing components to obtain agnostic looking tasks. Future interfaces planned are: VAL : this interface wraps VAL parser, which supports parsing of PDDL+ features. SAS+ : this interface is meant to support SAS representations natively. Since there is no SAS-based planning language, this will probably be useful to integrate planners into applications that are able to define SAS planning tasks programatically. Tarski : this interface will be used to parse, or build STIPS and more expressive models. Search engine components are meant to be modular, allowing users of LAPKT to assemble and combine features of different search engines to come up with customized search strategies, within reason and without sacrificing (much) efficiency. In order to do so, LAPKT makes heavy use of C++ templates and the Static Strategy design pattern.","title":"Overview"},{"location":"#news","text":"","title":"News!"},{"location":"#1m-solver-calls-planningdomains","text":"One of our planners, siw-then-bfs has reached over 1M calls in the remote solver handling the calls in the editor.planning.domains May 22, 2020","title":"1M solver calls @ planning.domains"},{"location":"#sparkle-planning-challenge-2019","text":"The Sparkle Planning Challenge automatically combines all participating planners into a state-of-the-art planning selector, and assesses the contribution of each participating planner to the performance of that planning selector. Results and Slides","title":"Sparkle Planning Challenge 2019"},{"location":"#winner-probe","text":"","title":"WINNER: PROBE"},{"location":"#runner-up-dual-bfws","text":"The planners that got the 1st and 2nd positions were PROBE (based on an early version of LAPKT) and DUAL-BFWS .","title":"RUNNER-UP: DUAL-BFWS"},{"location":"#international-planning-competition-ipc-2018","text":"Results and scores overview","title":"International Planning Competition (IPC) 2018"},{"location":"#winner-of-the-agile-track","text":"BFWS-preference corresponds to BFWS planner using option --BFWS-f5","title":"WINNER of the Agile Track"},{"location":"#runner-up-of-the-satisficing-track","text":"DUAL-BFWS corresponds to BFWS planner using option --DUAL-BFWS For more information about submitted BFWS planners, read this summary width-ipc-paper","title":"RUNNER-UP of the Satisficing Track"},{"location":"#ipc-2014-agile-track","text":"Once we fixed the bug on the submission of IPC'8 (International Planning Competition 2014), we were computing $h^2$ but not using it, our planners BFS_f, DFS+, and SIW+ are the fastest in the AGILE track (minimize CPU time) compared to the last winner, according to our experiments using the benchmarks from the competition.","title":"IPC 2014 Agile track"},{"location":"#contact-contributing","text":"We welcome anybody in the planning community to contribute into LAPKT, either by just using it or by submitting code implementing stuff they feel should be in an \\\"Automated Planning Toolkit\\\". We only request two things from you. First, to abide to the terms and conditions of the Apache License, Version 2.0, January 2004 (http://www.apache.org/licenses/). Second, to drop a note on us telling about what you plan to add or what you think should be changed. You can contribute to LAPKT by submitting code or discussing issues @ github . General questions: Miquel Ramirez and Nir Lipovetzky \\<firstname.surname\\@unimelb.edu.au>","title":"Contact &amp; Contributing"},{"location":"#citing-lapkt","text":"You can use cite LAPKT in your publications like this: @misc{lapkt, title = {{ Lightweight Automated Planning ToolKiT }} , author = {Miquel Ramirez and Nir Lipovetzky and Christian Muise}, howpublished = {\\url{http://lapkt.org/}}, year = {2015}, note = {Accessed: 2020} }","title":"Citing LAPKT"},{"location":"Atari/","text":"In this project we used width-based planning algorithms with a simulator instead of a PDDL description. We tested the planners on the The Atari 2600 games supported in The Arcade Learning Environment (ALE) -- a platform for AI research. See http://www.arcadelearningenvironment.org for details. Source Code Link Download the code at zip file or copy the repository using the following command git clone https://github.com/miquelramirez/ALE-Atari-Width.git <directory> will create a clone of the ALE master repository containing the game engine with the planners and the roms files of the tested games in <directory> . The directory is created if it does not yet exist. Atari Width-based planners Link The Classical Planning algorithms are located in: IW(1) Link src/agents/IW1Search.hpp src/agents/IW1Search.cpp 2BFS Link src/agents/BestFirstSearch.hpp src/agents/BestFirstSearch.cpp To compile, rename the makefile either for linux or mac Running ALE width-based planners Link The command to run IW1 is ./ale -display_screen true -discount_factor 0.995 -randomize_successor_novelty true -max_sim_steps_per_frame 150000 -player_agent search_agent -search_method iw1 (ROM_PATH)` The command to run 2BFS is ./ale -display_screen true -discount_factor 0.995 -randomize_successor_novelty true -max_sim_steps_per_frame 150000 -player_agent search_agent -search_method bfs (ROM_PATH)` and you have to substitute ROM_PATH for any of the games under supported_roms folder. max_sim_steps_per_frame* sets your budget, i.e. how many frames you can expand per lookahead. Each node is 5 frames of game play, so 150,000, is equivalent to 30,000 nodes generated. You don\\'t need that many to find rewards, so you can use a smaller number to play the game much faster. 150,000 was the parameter chosen by Bellemare et al. The most expensive computation is calling the simulator to generate the successor state. Python scripts Link We wrote scripts to make life easier for experimentation: - Evaluate_agents.py may help you to run experiments. We wrote some code to record the games, add the following flag to the ./ale command -record_trajectory true and then you can replay the game using - replay.py <state_trajectory_alg_game_episode.i file> Videos / papers Link Youtube Link You can watch the width-basd planners in Paper Link You can read more about it in the IJCAI 2015 paper Poster Link You can also have a quick introduction to the approach by looking at the poster presented in IJCAI too. Credits Link We want to thank Marc Bellemare for making the ALE code available and the research group at U. Alberta. The Classical Planning algorithms code is adapted from the Lightweight Automated Planning Toolkit (www.LAPKT.org). This project is a joint work by Nir Lipovetzky, Miquel Ramirez and Hector Geffner.","title":"Atari"},{"location":"Atari/#source-code","text":"Download the code at zip file or copy the repository using the following command git clone https://github.com/miquelramirez/ALE-Atari-Width.git <directory> will create a clone of the ALE master repository containing the game engine with the planners and the roms files of the tested games in <directory> . The directory is created if it does not yet exist.","title":"Source Code"},{"location":"Atari/#atari-width-based-planners","text":"The Classical Planning algorithms are located in:","title":"Atari Width-based planners"},{"location":"Atari/#iw1","text":"src/agents/IW1Search.hpp src/agents/IW1Search.cpp","title":"IW(1)"},{"location":"Atari/#2bfs","text":"src/agents/BestFirstSearch.hpp src/agents/BestFirstSearch.cpp To compile, rename the makefile either for linux or mac","title":"2BFS"},{"location":"Atari/#running-ale-width-based-planners","text":"The command to run IW1 is ./ale -display_screen true -discount_factor 0.995 -randomize_successor_novelty true -max_sim_steps_per_frame 150000 -player_agent search_agent -search_method iw1 (ROM_PATH)` The command to run 2BFS is ./ale -display_screen true -discount_factor 0.995 -randomize_successor_novelty true -max_sim_steps_per_frame 150000 -player_agent search_agent -search_method bfs (ROM_PATH)` and you have to substitute ROM_PATH for any of the games under supported_roms folder. max_sim_steps_per_frame* sets your budget, i.e. how many frames you can expand per lookahead. Each node is 5 frames of game play, so 150,000, is equivalent to 30,000 nodes generated. You don\\'t need that many to find rewards, so you can use a smaller number to play the game much faster. 150,000 was the parameter chosen by Bellemare et al. The most expensive computation is calling the simulator to generate the successor state.","title":"Running ALE width-based planners"},{"location":"Atari/#python-scripts","text":"We wrote scripts to make life easier for experimentation: - Evaluate_agents.py may help you to run experiments. We wrote some code to record the games, add the following flag to the ./ale command -record_trajectory true and then you can replay the game using - replay.py <state_trajectory_alg_game_episode.i file>","title":"Python scripts"},{"location":"Atari/#videos-papers","text":"","title":"Videos / papers"},{"location":"Atari/#youtube","text":"You can watch the width-basd planners in","title":"Youtube"},{"location":"Atari/#paper","text":"You can read more about it in the IJCAI 2015 paper","title":"Paper"},{"location":"Atari/#poster","text":"You can also have a quick introduction to the approach by looking at the poster presented in IJCAI too.","title":"Poster"},{"location":"Atari/#credits","text":"We want to thank Marc Bellemare for making the ALE code available and the research group at U. Alberta. The Classical Planning algorithms code is adapted from the Lightweight Automated Planning Toolkit (www.LAPKT.org). This project is a joint work by Nir Lipovetzky, Miquel Ramirez and Hector Geffner.","title":"Credits"},{"location":"credits/","text":"The Lightweight Automated Planning Toolkit (LAPKT) is the result of a major effort to develop a framework for writing domain-independent planners which offered clean and clear programming interfaces. The inspiration for investing time & effort into this is that we (Miquel Ram\u00edrez and Nir Lipovetzky) wanted to work in an environment which constrained us the least. We didn't feel too comfortable developing our research by just \"commenting out\" stuff in existing planning systems and introducing ours. We develop our research on top of LAPKT, so over time we will be adding whatever we found to be useful and wasn't already present in the toolkit. We would like to thank Hector Geffner, as great part of the toolkit was developed when we were his PhD. Students. Since 2013 It has been kindly supported by the Australian Research Council linkage grant LP11010015 (Peter J. Stuckey and Adrian R. Pearce), Department of Computing and Information Systems, The University of Melbourne. We would like to thank the following people for having contributed (indirectly) to this toolkit by having provided us with ideas on \"how to write a planner\" by publishing or sharing their own planning systems. In no particular order: Blai Bonet Joerg Hoffman Patrik Haslum Malte Helmert Contributors: Miquel Ramirez, Nir Lipovetzky, Christian Muise Branding: Thanks Vaishak Belle, LAPKT ([lapkat]) fixed our previous unpronounceable LWAPTK acronym . Thanks Angela Rojas for creating the great Logo over dinner. Quoting Joerg's remark on FF source code, \"have fun\"!","title":"Credits"},{"location":"gettingStarted/","text":"Getting Started Link You have two options available 1) Get a working code base container using Docker, or 2) Download the source code and its dependencies. Docker Link For Multi-platform execution (Windows, MAC, Linux, Azure, AWS) You can quickly get a contained working copy in few minutes of the latest LAPKT version in the repository using Docker. For instructions, please visit: https://hub.docker.com/r/lapkt/lapkt-public/ Download sources Link The command: git clone https://github.com/LAPKT-dev/LAPKT-public.git <directory> will create a clone of the LAPKT master repository in <directory> . The directory is created if it does not yet exist. Requirements Link LAPKT requires the following libraries & tools: scons boost boost::program_options varjudy optional FF-parser: makedepend flex bison optional FD-Parser: python python-dev boost::python-dev In order to compile LAPKT, we recommend g++ 4.7 or better. However, any compiler able to handle both boost libraries and C++11 standard new features, should also be usable (we have been able to compile it under Visual Studio 2010, llvm, and the new Linux bash shell on windows 10). makedepend comes in xutils-dev package. Building LAPKT Link In order to build LAPKT you need to install scons (a GNU Makefile replacement) in your system. Refer to http://www.scons.org for directions on how to achieve this. In order to compile some of the examples, you will also need a version >= 1.49 of the Boost C++ libraries available on your system. You can check the version you have either manually by looking at the macro defined in boost/version.hpp or, on debian systems, by running dpkg -s libboost-dev . Finally, LAPKT requires the Judy library (http://judy.sourceforge.net/index.html) to support the bitmap array class 'Varset Judy'. NOTE: This dependency will be optional or entirely deprecated in the future. The following command installs all the dependencies on Ubuntu version > 12.04LTS: sudo apt-get update && sudo apt-get install --no-install-recommends -y \\ build-essential \\ ca-certificates \\ xutils-dev \\ scons \\ gcc-multilib \\ flex \\ bison \\ python \\ python-dev \\ python3 \\ python3-dev \\ libboost-python-dev \\ libboost-dev \\ libjudy-dev \\ libboost-program-options-dev \\ g++-multilib Build Instructions Link Issue the command scons at the root of the source directory to obtain the (static) library containing essential data structures and other miscellaneous utilities. If debug symbols are needed, the command scons debug=1 builds the library with optimizations disabled and debug symbols enabled. If you want to use FF-parser, compile the ff into a library by running the following commands: cd external/libff make clean make depend make If you are a Mac OS X user, run this command to create the final dynamic library libtool -o libff.a *.o As Mac OS X don\\'t like static libraries, if you run scons and you get the following error: ld : library not found for - lcrt0 . o edit the SConstruct and comment (add #) the following line: common_env.Append( LINKFLAGS = [ '-static' ] ) Compiling Examples and Planners Link To compile any example go to a specific folder and type scons In FD-parser based examples type ./build.py The examples for the 'planner agnostic' interface can be found on examples/agnostic-examples and cover the following topics: * agnostic - examples / assembling_strips_problems Shows how to define a STRIPS planning problem programatically . * agnostic - examples / successor_generation Discusses the different way of generating successors during search . * agnostic - examples / bfs * agnostic - examples / bfs - double - queue * agnostic - examples / bfs - double - queue - secondary - heuristic Shows how can one assemble available components to deliver a planner built around a BFS search engine , with multiple queues and secondary heuristics , on a parametrized planning task . * agnostic - examples / das Shows how can one assemble available components to deliver a planner built around Deadline Aware Search . Alternatively, To learn how to ensemble different heuristics go through simple planners like planners/generic-best_first-ffparser To learn how to use or create a planner using FD-parser, copy and edit a simple planner like planners/siw and to learn how to use or create a planner using FF-parser examples/ff-interface or copy and edit a simple Breadth first search planner like examples/agnostic-examples/brfs or start from the classic heuristic Search Planner examples / agnostic - examples / bfs - hmax Shows how to assemble a best - first search using h_max with multiple modes : greedy / delayed / anytime , over a task specified in PDDL and parsed by FF - parser","title":"Getting Started"},{"location":"gettingStarted/#getting-started","text":"You have two options available 1) Get a working code base container using Docker, or 2) Download the source code and its dependencies.","title":"Getting Started"},{"location":"gettingStarted/#docker","text":"For Multi-platform execution (Windows, MAC, Linux, Azure, AWS) You can quickly get a contained working copy in few minutes of the latest LAPKT version in the repository using Docker. For instructions, please visit: https://hub.docker.com/r/lapkt/lapkt-public/","title":"Docker"},{"location":"gettingStarted/#download-sources","text":"The command: git clone https://github.com/LAPKT-dev/LAPKT-public.git <directory> will create a clone of the LAPKT master repository in <directory> . The directory is created if it does not yet exist.","title":"Download sources"},{"location":"gettingStarted/#requirements","text":"LAPKT requires the following libraries & tools: scons boost boost::program_options varjudy optional FF-parser: makedepend flex bison optional FD-Parser: python python-dev boost::python-dev In order to compile LAPKT, we recommend g++ 4.7 or better. However, any compiler able to handle both boost libraries and C++11 standard new features, should also be usable (we have been able to compile it under Visual Studio 2010, llvm, and the new Linux bash shell on windows 10). makedepend comes in xutils-dev package.","title":"Requirements"},{"location":"gettingStarted/#building-lapkt","text":"In order to build LAPKT you need to install scons (a GNU Makefile replacement) in your system. Refer to http://www.scons.org for directions on how to achieve this. In order to compile some of the examples, you will also need a version >= 1.49 of the Boost C++ libraries available on your system. You can check the version you have either manually by looking at the macro defined in boost/version.hpp or, on debian systems, by running dpkg -s libboost-dev . Finally, LAPKT requires the Judy library (http://judy.sourceforge.net/index.html) to support the bitmap array class 'Varset Judy'. NOTE: This dependency will be optional or entirely deprecated in the future. The following command installs all the dependencies on Ubuntu version > 12.04LTS: sudo apt-get update && sudo apt-get install --no-install-recommends -y \\ build-essential \\ ca-certificates \\ xutils-dev \\ scons \\ gcc-multilib \\ flex \\ bison \\ python \\ python-dev \\ python3 \\ python3-dev \\ libboost-python-dev \\ libboost-dev \\ libjudy-dev \\ libboost-program-options-dev \\ g++-multilib","title":"Building LAPKT"},{"location":"gettingStarted/#build-instructions","text":"Issue the command scons at the root of the source directory to obtain the (static) library containing essential data structures and other miscellaneous utilities. If debug symbols are needed, the command scons debug=1 builds the library with optimizations disabled and debug symbols enabled. If you want to use FF-parser, compile the ff into a library by running the following commands: cd external/libff make clean make depend make If you are a Mac OS X user, run this command to create the final dynamic library libtool -o libff.a *.o As Mac OS X don\\'t like static libraries, if you run scons and you get the following error: ld : library not found for - lcrt0 . o edit the SConstruct and comment (add #) the following line: common_env.Append( LINKFLAGS = [ '-static' ] )","title":"Build Instructions"},{"location":"gettingStarted/#compiling-examples-and-planners","text":"To compile any example go to a specific folder and type scons In FD-parser based examples type ./build.py The examples for the 'planner agnostic' interface can be found on examples/agnostic-examples and cover the following topics: * agnostic - examples / assembling_strips_problems Shows how to define a STRIPS planning problem programatically . * agnostic - examples / successor_generation Discusses the different way of generating successors during search . * agnostic - examples / bfs * agnostic - examples / bfs - double - queue * agnostic - examples / bfs - double - queue - secondary - heuristic Shows how can one assemble available components to deliver a planner built around a BFS search engine , with multiple queues and secondary heuristics , on a parametrized planning task . * agnostic - examples / das Shows how can one assemble available components to deliver a planner built around Deadline Aware Search . Alternatively, To learn how to ensemble different heuristics go through simple planners like planners/generic-best_first-ffparser To learn how to use or create a planner using FD-parser, copy and edit a simple planner like planners/siw and to learn how to use or create a planner using FF-parser examples/ff-interface or copy and edit a simple Breadth first search planner like examples/agnostic-examples/brfs or start from the classic heuristic Search Planner examples / agnostic - examples / bfs - hmax Shows how to assemble a best - first search using h_max with multiple modes : greedy / delayed / anytime , over a task specified in PDDL and parsed by FF - parser","title":"Compiling Examples and Planners"},{"location":"modules/","text":"Modules and Planners Link Planners Link Planners by default use the FD parser. A version of each planner exist using FF parser instead. 3 planners where submitted to Satisficing and Agile track in IPC 2014. They support action costs and Conditional Effects. See Documentation#Parsers_Supported to know how to tell the parser to ignore or account for action costs. FF Link FF planner as described in JAIR 2001. Goal agenda is not computed by default. FF-parser planners / ff - ffparser Command : . / ff --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --output arg Output file for plan BFS_f Link Greedy Best First Search Planner that uses f(n) = novelty(n), breaking ties with lm_count(n) and h_rel_plan(n). described in Lipovetzky et al. at ECAI 2012 FD-parser planners / bfs_f Command : . / bfs . py < domain_file > < problem_file > < plan_output > Ignores costs : . / bfs_f_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / bfs_f - ffparser Command : . / bfs_f --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=2) Max width w for novelty (default 2) --output arg Output file for plan --one-ha-per-fluent arg (=0) Extract only one helpful action per fluent --use-original-ff-heur arg (=0) Use original FF heuristic computed by layers Anytime BFS_f Link Runs First SIW, then BFS_f with the bound found by SIW, and finally an anytime version using RWA* described in IPC 2014 Booklet FD-parser planners / at_bfs_f Command : . / at_bfs . py < domain_file > < problem_file > < plan_output > . / at_bfs_f - 2 - no - bfs_f . py < domain_file > < problem_file > < plan_output > . / at_bfs_f - 2 - no - siw . py < domain_file > < problem_file > < plan_output > . / at_bfs_f - no - siw - no - bfs_f . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / at_bfs_f - ffparser Command : . / at_bfs_f --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --iw-bound arg (=2) Max width w for SIW (default 2) --max-novelty arg (=2) Max width w for novelty heuristic in BFS(f) ( default 2 ) --output arg Output file for plan --one-ha-per-fluent arg (=0) Extract only one helpful action per fluent --disable-siw arg (=0) Disable SIW stage --disable-bfs-f arg (=0) Disable BFS(f) stage Blind & Width-Based Search Planners Link IW Link Iterative Width is a blind search planner that exploits the low width of classical benchmark when goals are atomic. For conjuctive goals look at SIW, SIW+ or DFS+ described in Lipovetzky et al. at ECAI 2012 FD-parser planners / iw Command : . / iw . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / iw - ffparser Command : . / iw --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=1) Max width w for IW(w) --atomic arg (=1) Runs IW(w) over each atomic goal of the problem (bool) --output arg Output plan file IW Plus Link IW+ relaxes IW novelty pruning. described in Lipovetzky et al. at ECAI 2014 FD-parser planners / iw Command : . / rp_iw . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / iw - ffparser Command : . / rp_iw --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=2) Max width w for IW(w) --output arg Output plan file SIW Link Serialized Iterative Width is a blind search planner competitive that exploits the low width of classical benchmark through IW and simple goal serialization described in Lipovetzky et al. at ECAI 2012 FD-parser planners / siw Command : . / siw . py < domain_file > < problem_file > < plan_output > Ignores costs : . / siw_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / siw - ffparser Command : . / siw --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=1) Max width w for IW(w) --output arg Output plan file SIW Plus Link SIW+ relaxes IW novelty pruning. Blind Search Planner with high performance, closer to FF over IPC\\'11 benchmark described in Lipovetzky et al. at ECAI 2014 FD-parser planners / siw_plus Command : . / siw_plus . py < domain_file > < problem_file > < plan_output > Ignores costs : . / siw_plus_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / siw_plus - ffparser Command : . / siw_plus --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=1) Max width w for IW(w) --output arg Output plan file DFS Plus Link DFS+ Extends SIW+ Goal serialization. Blind Search planner with high performance, closer to LAMA\\'11 and BFS_f over IPC\\'11 benchmark described in Lipovetzky et al. at ECAI 2014 FD-parser planners / dfs_plus Command : . / dfs_plus . py < domain_file > < problem_file > < plan_output > Ignores costs : . / dfs_plus_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / dfs_plus - ffparser Command : . / dfs_plus --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=2) Max width w for IW(w) --output arg Output plan file Generic BFS with Optional Heuristics Link By default BFS is set to GBFS FF-parser planners / generic - best_first - ffparser Command : . / bfs --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --heuristic arg (=1) 1: H_add (default 1) 2 : H_add_Rp 3 : H_max_Rp 4 : H_add_FF_Rp 5 : H_max_FF_Rp 6 : H_layered_FF_Rp ( FF_ * , as in Journal Paper ) --anytime arg (=0) Anytime (default False) --output arg Output file for plan Search Algorithms Implemented Link All Search Algorithms implement Forward Search by accessing interfaces/agnostic/fwd_search_prob.hxx decoupling the search algrotihm from successor generation, applicability function, etc. Intended to easily run this algorithms on backward search. Blind Search Link No use of heuristics. Breadth-First search Link include/aptk/brfs.hxx Width-Based Search Link described in Lipovetzky et al. at ECAI 2012 , and Lipovetzky et al. at ECAI 2014 Iterated Width Link Breadth-First search with novelty pruning. include/aptk/iw.hxx Iterated Width Plus Link Breadth-First search with a relaxed novelty pruning. include/aptk/rp_iw.hxx Serialized Iterated Width Link Uses iterated width to both solve and serialize the goals. The serialization is a form of Hill-Climbing over the set of goals include/aptk/siw.hxx Serialized Iterated Width Plus Link Uses iterated width plus to both solve and serialize the goals. The serialization is a form of Hill-Climbing over the set of goals include/aptk/siw_plus.hxx Depth-first Search Width Link Uses iterated width to both solve and serialize the goals. DFS in the space of serialization induced by bounded Iterative Width. include/aptk/dfs_plus.hxx Heuristic Search Link Best-First search Link Greedy Best First Search Link include/aptk/at_gbfs.hxx Any-time Best First Search Link include/aptk/at_bfs.hxx Any-time Best First Search with two open lists Link include/aptk/at_bfs_dq.hxx The PREFERRED list, for nodes generated by preferred operators, and the OPEN list, for the rest. Best First Search with three open lists and two heuristic estimators Link include/aptk/at_bfs_dq_mh.hxx The search frontier is split into three lists: BOTH: holds nodes generated by actions deemed as \\'preferred\\' by both heuristic estimators PREFERRED: holds nodes generated by actions deemed as \\'preferred\\' by the primary heuristic estimator OPEN: holds nodes generated by actions not deemed as \\'preferred\\' by the primary heuristic estimator Any-time Weighted A* Link Weight W decaying according to fixed decay parameter. Variants include single queue and multiple queue (either with one or two heuristic estimators). include/aptk/at_wbfs.hxx include/aptk/at_wbfs_dq.hxx include/aptk/at_wbfs_dq_mh.hxx Any-time Restarting Weighted A* Link described in Ricther et al. at ICAPS 2010 with weight W decaying according to fixed decay parameter. Variants include single queue and multiple queue (either with one or two heuristic estimators). include/aptk/at_rwbfs.hxx include/aptk/at_rwbfs_dq.hxx include/aptk/at_rwbfs_dq_mh.hxx Contract Search Link The Deadline Aware Search algorithm Link described in Dionne et al. at SOCS 2011 include/aptk/das.hxx EHC Link Enforced Hill Climbing as in JAIR 2001. include/aptk/ff_ehc.hxx Heuristics Implemented Link Critical Paths Link h\\^1 Link interfaces/agnostic/h_1.hxx h\\^2 Link interfaces/agnostic/h_2.hxx Delete Relaxations Link h_max / h_add Link Same implementation as h\\^1. h_add and h_max differ only through the evaluation function, which can be specified. Dijskstra Based implementation interfaces/agnostic/h_1.hxx Relaxed Planning Graph implementation interfaces/agnostic/layered_h_max.hxx h\\^ff Link Original FF heuristic computation from JAIR 2001 paper interfaces/agnostic/ff_rp_heuristic.hxx Relaxed Planning Graph Heuristics Link Computes relaxed plan heuristics backwards from the goal based on best_supporters function. Keyder et al. ECAI 2008 h_1 and h_add natively define best supporters, although other heuristics could be used too. interfaces/agnostic/rp_heuristic.hxx h\\^C Link Semi Relaxed Heuristic by introducing special fluents that explicitly represent conjunctions of fluents Keyder et al. ICAPS 2012 interfaces/agnostic/h_C.hxx Counting heuristic Link Unachieved Goals Link Counts the number of unachieved goals interfaces/agnostic/h_unsat.hxx Unachieved Landmarks Link Counts the number of unachieved landmarks. Landmark graph is built from And/Or Graphs Keyder et al. ECAI 2010 interfaces/agnostic/landmark_count.hxx Novelty Link Counts the size of the smallest tuple made true by a given state for the first time in the search Lipovetzky et al. at ECAI 2012 interfaces/agnostic/novelty.hxx Novelty Plus Link Relaxed versioin of Novelty Lipovetzky et al. at ECAI 2014 interfaces/agnostic/novelty.hxx Reachability Link Naive implementation for testing reachability interfaces/agnostic/reachability.hxx Watchlist-based implementation for testing reachability: interfaces/agnostic/watch_list_succ_gen.hxx (see the \\\"is_reachable(const State&)\\\" method) Parsers Supported Link We currently ported FF-Parser and FD-Parser FF Parser Link FF-Parser is based on bison and flex. It\\'s compiled as an independent library in external/libff and connected to the toolkit in interfaces/ff-wrapped/ff_to_aptk.hxx interfaces/ff-wrapped/ff_to_aptk.hxx creating a STRIPS Problem instance. Action costs can be ignored by setting the ignore_action_costs = true void get_problem_description ( std :: string pddl_domain_path , std :: string pddl_problem_path , STRIPS_Problem & strips_problem , bool ignore_action_costs = false , bool get_detailed_fluent_names = false ); aptk :: FF_Parser :: get_problem_description (..., true ) FD-parser Link FD-Parser is written in python. It\\'s located in external/fd and connected to the toolkit in planners/python/agnostic/py_strips_prob.hxx planners/python/agnostic/py_strips_prob.cxx creating a STRIPS Problem instance. Action costs can be ignored by setting in your python script task.ignore_action_costs = True as it\\'s done for example in /planners/bfs_f/bfs_f_unit_cost.py Problem Representation (STRIPS Model) Link STRIPS Problem and useful information like mutexes (if computed) Link interfaces/agnostic/strips_prob.cxx interfaces/agnostic/strips_prob.hxx STRIPS States Link interfaces/agnostic/strips_state.cxx interfaces/agnostic/strips_state.hxx Actions and Fluents Link interfaces / agnostic / fluent . cxx interfaces / agnostic / fluent . hxx interfaces / agnostic / action . cxx interfaces / agnostic / action . hxx interfaces / agnostic / cond_eff . cxx interfaces / agnostic / cond_eff . hxx Successor Generator Link interfaces/agnostic/succ_gen.cxx interfaces/agnostic/succ_gen.hxx Running Experiments Link Scripts for running experiments, profiling, benchmarking and creating tables with Coverage, IPC Time and Quality Score are available benchmarks / run . py # Dependencies / Prerequisites : # - valgrind # - timeout # - dot ( graphviz ) # - krtoolkit Usage : python run . py profile < executable > < ipc directory > [ < domain pddl > < problem pddl > ] python run . py benchmark < executable > < ipc directory > < results directory > [ < domain > ] python run . py compare < directories with , separated > < ipc directory > python run . py clean Some Benchmark domains can be found at benchmarks/ipc-2006/ benchmarks/ipc-2011/ benchmarks/ipc-2014/ To use run.py script over new sets of benchmarks instead of specific domains, edit benchmarks/domains.py Examples Link FF-Interface Example Link The example for the 'ff parser' interface can be found on * examples/ff-interface FD-Interface Example Link The example for the 'fD parser' interface can be found on * examples/fd-interface This is a very simple example that shows the basics for interfacing lwaptk with Fast Downward parser. In order to build the example issue the command: $ ./build.py and to run the example: $ ./parser.py <path to pddl domain file> <path to pddl problem file> if everything is working as it should, you should see FD parsing output on the standard output, as well as a dump of the grounded actions. Note that this will copy the folder externals/fd to the local directory, so DO NOT add it to the repository. If you need to do customize Fast Downward parsing scripts, just edit build.py to avoid it clobbering your local copy. Agnostic Interface Examples Link The examples for the 'planner agnostic' interface can be found on examples/agnostic-examples and cover the following topics: Assembling STRIPS problem programatically Link Shows how to define a STRIPS planning problem programatically. * agnostic-examples/assembling_strips_problems Successor Generators Link Discusses and compares different ways of generating successors during search. * agnostic-examples/successor_generation Open Lists Link Discusses and compares different ways of creating open lists for your search algortithm. * agnostic-examples/fibonacci_open BFS engine variations Link Shows how can one assemble available components to deliver a planner built around a BFS search engine, with multiple queues and secondary heuristics, on a parametrized planning task. * agnostic-examples/bfs * agnostic-examples/bfs-double-queue * agnostic-examples/bfs-double-queue-secondary-heuristic BFS + h_max (greedy|delayed|anytime) + FF-parser Link Shows how to assemble a classic planner: best-first search using h_max with multiple modes: greedy/delayed/anytime, over a task specified in PDDL and parsed by FF-parser * agnostic-examples/bfs-hmax WA* variations + landmarks Link Shows how can one assemble available components to deliver a planner built around a WA* search engine, with multiple queues and secondary heuristics, on a parametrized planning task. Illustrates as well how to use landmark count heurstic. * agnostic-examples/wa-planner * agnostic-examples/rwa-planner Deadline Aware Search engine Link Shows how can one assemble available components to deliver a planner built around Deadline Aware Search. * agnostic-examples/das Breadth-First search + FF-parser Link Shows how can one assemble available components to deliver a blind search planner. * agnostic-examples/brfs h_C compilations + FF-parser Link Shows how can one use the \\Pi_C compilation to compute the h_C heuristic. Keyder et al. ICAPS 2012 * agnostic-examples/h_C_heuristics Replanner (changing init and goal situation on the fly) Link Shows how to create a replanner. It illustrates how to change the initial and goal states without having to parse the problem again, solving it with bfs+h_max. In the example we change the initial and goal situations by applying the first action of the current plan to progress the initial state, and last action of the plan to regress the goal. * agnostic-examples/replanner Width-Based algorithm + FD parser Link Shows how SIW is implemented, using novelty function and FD parser * planners/siw","title":"Modules and Planners"},{"location":"modules/#modules-and-planners","text":"","title":"Modules and Planners"},{"location":"modules/#planners","text":"Planners by default use the FD parser. A version of each planner exist using FF parser instead. 3 planners where submitted to Satisficing and Agile track in IPC 2014. They support action costs and Conditional Effects. See Documentation#Parsers_Supported to know how to tell the parser to ignore or account for action costs.","title":"Planners"},{"location":"modules/#ff","text":"FF planner as described in JAIR 2001. Goal agenda is not computed by default. FF-parser planners / ff - ffparser Command : . / ff --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --output arg Output file for plan","title":"FF"},{"location":"modules/#bfs_f","text":"Greedy Best First Search Planner that uses f(n) = novelty(n), breaking ties with lm_count(n) and h_rel_plan(n). described in Lipovetzky et al. at ECAI 2012 FD-parser planners / bfs_f Command : . / bfs . py < domain_file > < problem_file > < plan_output > Ignores costs : . / bfs_f_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / bfs_f - ffparser Command : . / bfs_f --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=2) Max width w for novelty (default 2) --output arg Output file for plan --one-ha-per-fluent arg (=0) Extract only one helpful action per fluent --use-original-ff-heur arg (=0) Use original FF heuristic computed by layers","title":"BFS_f"},{"location":"modules/#anytime-bfs_f","text":"Runs First SIW, then BFS_f with the bound found by SIW, and finally an anytime version using RWA* described in IPC 2014 Booklet FD-parser planners / at_bfs_f Command : . / at_bfs . py < domain_file > < problem_file > < plan_output > . / at_bfs_f - 2 - no - bfs_f . py < domain_file > < problem_file > < plan_output > . / at_bfs_f - 2 - no - siw . py < domain_file > < problem_file > < plan_output > . / at_bfs_f - no - siw - no - bfs_f . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / at_bfs_f - ffparser Command : . / at_bfs_f --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --iw-bound arg (=2) Max width w for SIW (default 2) --max-novelty arg (=2) Max width w for novelty heuristic in BFS(f) ( default 2 ) --output arg Output file for plan --one-ha-per-fluent arg (=0) Extract only one helpful action per fluent --disable-siw arg (=0) Disable SIW stage --disable-bfs-f arg (=0) Disable BFS(f) stage","title":"Anytime BFS_f"},{"location":"modules/#blind-width-based-search-planners","text":"","title":"Blind &amp; Width-Based Search Planners"},{"location":"modules/#iw","text":"Iterative Width is a blind search planner that exploits the low width of classical benchmark when goals are atomic. For conjuctive goals look at SIW, SIW+ or DFS+ described in Lipovetzky et al. at ECAI 2012 FD-parser planners / iw Command : . / iw . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / iw - ffparser Command : . / iw --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=1) Max width w for IW(w) --atomic arg (=1) Runs IW(w) over each atomic goal of the problem (bool) --output arg Output plan file","title":"IW"},{"location":"modules/#iw-plus","text":"IW+ relaxes IW novelty pruning. described in Lipovetzky et al. at ECAI 2014 FD-parser planners / iw Command : . / rp_iw . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / iw - ffparser Command : . / rp_iw --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=2) Max width w for IW(w) --output arg Output plan file","title":"IW Plus"},{"location":"modules/#siw","text":"Serialized Iterative Width is a blind search planner competitive that exploits the low width of classical benchmark through IW and simple goal serialization described in Lipovetzky et al. at ECAI 2012 FD-parser planners / siw Command : . / siw . py < domain_file > < problem_file > < plan_output > Ignores costs : . / siw_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / siw - ffparser Command : . / siw --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=1) Max width w for IW(w) --output arg Output plan file","title":"SIW"},{"location":"modules/#siw-plus","text":"SIW+ relaxes IW novelty pruning. Blind Search Planner with high performance, closer to FF over IPC\\'11 benchmark described in Lipovetzky et al. at ECAI 2014 FD-parser planners / siw_plus Command : . / siw_plus . py < domain_file > < problem_file > < plan_output > Ignores costs : . / siw_plus_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / siw_plus - ffparser Command : . / siw_plus --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=1) Max width w for IW(w) --output arg Output plan file","title":"SIW Plus"},{"location":"modules/#dfs-plus","text":"DFS+ Extends SIW+ Goal serialization. Blind Search planner with high performance, closer to LAMA\\'11 and BFS_f over IPC\\'11 benchmark described in Lipovetzky et al. at ECAI 2014 FD-parser planners / dfs_plus Command : . / dfs_plus . py < domain_file > < problem_file > < plan_output > Ignores costs : . / dfs_plus_unit_cost . py < domain_file > < problem_file > < plan_output > Options specified inside the script FF-parser planners / dfs_plus - ffparser Command : . / dfs_plus --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --bound arg (=2) Max width w for IW(w) --output arg Output plan file","title":"DFS Plus"},{"location":"modules/#generic-bfs-with-optional-heuristics","text":"By default BFS is set to GBFS FF-parser planners / generic - best_first - ffparser Command : . / bfs --domain <domain_file> --problem <problem_file> --output <plan_output> Options :: --help Show help message --domain arg Input PDDL domain description --problem arg Input PDDL problem description --heuristic arg (=1) 1: H_add (default 1) 2 : H_add_Rp 3 : H_max_Rp 4 : H_add_FF_Rp 5 : H_max_FF_Rp 6 : H_layered_FF_Rp ( FF_ * , as in Journal Paper ) --anytime arg (=0) Anytime (default False) --output arg Output file for plan","title":"Generic BFS with Optional Heuristics"},{"location":"modules/#search-algorithms-implemented","text":"All Search Algorithms implement Forward Search by accessing interfaces/agnostic/fwd_search_prob.hxx decoupling the search algrotihm from successor generation, applicability function, etc. Intended to easily run this algorithms on backward search.","title":"Search Algorithms Implemented"},{"location":"modules/#blind-search","text":"No use of heuristics.","title":"Blind Search"},{"location":"modules/#breadth-first-search","text":"include/aptk/brfs.hxx","title":"Breadth-First search"},{"location":"modules/#width-based-search","text":"described in Lipovetzky et al. at ECAI 2012 , and Lipovetzky et al. at ECAI 2014","title":"Width-Based Search"},{"location":"modules/#iterated-width","text":"Breadth-First search with novelty pruning. include/aptk/iw.hxx","title":"Iterated Width"},{"location":"modules/#iterated-width-plus","text":"Breadth-First search with a relaxed novelty pruning. include/aptk/rp_iw.hxx","title":"Iterated Width Plus"},{"location":"modules/#serialized-iterated-width","text":"Uses iterated width to both solve and serialize the goals. The serialization is a form of Hill-Climbing over the set of goals include/aptk/siw.hxx","title":"Serialized Iterated Width"},{"location":"modules/#serialized-iterated-width-plus","text":"Uses iterated width plus to both solve and serialize the goals. The serialization is a form of Hill-Climbing over the set of goals include/aptk/siw_plus.hxx","title":"Serialized Iterated Width Plus"},{"location":"modules/#depth-first-search-width","text":"Uses iterated width to both solve and serialize the goals. DFS in the space of serialization induced by bounded Iterative Width. include/aptk/dfs_plus.hxx","title":"Depth-first Search Width"},{"location":"modules/#heuristic-search","text":"","title":"Heuristic Search"},{"location":"modules/#best-first-search","text":"","title":"Best-First search"},{"location":"modules/#greedy-best-first-search","text":"include/aptk/at_gbfs.hxx","title":"Greedy Best First Search"},{"location":"modules/#any-time-best-first-search","text":"include/aptk/at_bfs.hxx","title":"Any-time Best First Search"},{"location":"modules/#any-time-best-first-search-with-two-open-lists","text":"include/aptk/at_bfs_dq.hxx The PREFERRED list, for nodes generated by preferred operators, and the OPEN list, for the rest.","title":"Any-time Best First Search with two open lists"},{"location":"modules/#best-first-search-with-three-open-lists-and-two-heuristic-estimators","text":"include/aptk/at_bfs_dq_mh.hxx The search frontier is split into three lists: BOTH: holds nodes generated by actions deemed as \\'preferred\\' by both heuristic estimators PREFERRED: holds nodes generated by actions deemed as \\'preferred\\' by the primary heuristic estimator OPEN: holds nodes generated by actions not deemed as \\'preferred\\' by the primary heuristic estimator","title":"Best First Search with three open lists and two heuristic estimators"},{"location":"modules/#any-time-weighted-a","text":"Weight W decaying according to fixed decay parameter. Variants include single queue and multiple queue (either with one or two heuristic estimators). include/aptk/at_wbfs.hxx include/aptk/at_wbfs_dq.hxx include/aptk/at_wbfs_dq_mh.hxx","title":"Any-time Weighted A*"},{"location":"modules/#any-time-restarting-weighted-a","text":"described in Ricther et al. at ICAPS 2010 with weight W decaying according to fixed decay parameter. Variants include single queue and multiple queue (either with one or two heuristic estimators). include/aptk/at_rwbfs.hxx include/aptk/at_rwbfs_dq.hxx include/aptk/at_rwbfs_dq_mh.hxx","title":"Any-time Restarting Weighted A*"},{"location":"modules/#contract-search","text":"","title":"Contract Search"},{"location":"modules/#the-deadline-aware-search-algorithm","text":"described in Dionne et al. at SOCS 2011 include/aptk/das.hxx","title":"The Deadline Aware Search algorithm"},{"location":"modules/#ehc","text":"Enforced Hill Climbing as in JAIR 2001. include/aptk/ff_ehc.hxx","title":"EHC"},{"location":"modules/#heuristics-implemented","text":"","title":"Heuristics Implemented"},{"location":"modules/#critical-paths","text":"","title":"Critical Paths"},{"location":"modules/#h1","text":"interfaces/agnostic/h_1.hxx","title":"h\\^1"},{"location":"modules/#h2","text":"interfaces/agnostic/h_2.hxx","title":"h\\^2"},{"location":"modules/#delete-relaxations","text":"","title":"Delete Relaxations"},{"location":"modules/#h_max-h_add","text":"Same implementation as h\\^1. h_add and h_max differ only through the evaluation function, which can be specified. Dijskstra Based implementation interfaces/agnostic/h_1.hxx Relaxed Planning Graph implementation interfaces/agnostic/layered_h_max.hxx","title":"h_max / h_add"},{"location":"modules/#hff","text":"Original FF heuristic computation from JAIR 2001 paper interfaces/agnostic/ff_rp_heuristic.hxx","title":"h\\^ff"},{"location":"modules/#relaxed-planning-graph-heuristics","text":"Computes relaxed plan heuristics backwards from the goal based on best_supporters function. Keyder et al. ECAI 2008 h_1 and h_add natively define best supporters, although other heuristics could be used too. interfaces/agnostic/rp_heuristic.hxx","title":"Relaxed Planning Graph Heuristics"},{"location":"modules/#hc","text":"Semi Relaxed Heuristic by introducing special fluents that explicitly represent conjunctions of fluents Keyder et al. ICAPS 2012 interfaces/agnostic/h_C.hxx","title":"h\\^C"},{"location":"modules/#counting-heuristic","text":"","title":"Counting heuristic"},{"location":"modules/#unachieved-goals","text":"Counts the number of unachieved goals interfaces/agnostic/h_unsat.hxx","title":"Unachieved Goals"},{"location":"modules/#unachieved-landmarks","text":"Counts the number of unachieved landmarks. Landmark graph is built from And/Or Graphs Keyder et al. ECAI 2010 interfaces/agnostic/landmark_count.hxx","title":"Unachieved Landmarks"},{"location":"modules/#novelty","text":"Counts the size of the smallest tuple made true by a given state for the first time in the search Lipovetzky et al. at ECAI 2012 interfaces/agnostic/novelty.hxx","title":"Novelty"},{"location":"modules/#novelty-plus","text":"Relaxed versioin of Novelty Lipovetzky et al. at ECAI 2014 interfaces/agnostic/novelty.hxx","title":"Novelty Plus"},{"location":"modules/#reachability","text":"Naive implementation for testing reachability interfaces/agnostic/reachability.hxx Watchlist-based implementation for testing reachability: interfaces/agnostic/watch_list_succ_gen.hxx (see the \\\"is_reachable(const State&)\\\" method)","title":"Reachability"},{"location":"modules/#parsers-supported","text":"We currently ported FF-Parser and FD-Parser","title":"Parsers Supported"},{"location":"modules/#ff-parser","text":"FF-Parser is based on bison and flex. It\\'s compiled as an independent library in external/libff and connected to the toolkit in interfaces/ff-wrapped/ff_to_aptk.hxx interfaces/ff-wrapped/ff_to_aptk.hxx creating a STRIPS Problem instance. Action costs can be ignored by setting the ignore_action_costs = true void get_problem_description ( std :: string pddl_domain_path , std :: string pddl_problem_path , STRIPS_Problem & strips_problem , bool ignore_action_costs = false , bool get_detailed_fluent_names = false ); aptk :: FF_Parser :: get_problem_description (..., true )","title":"FF Parser"},{"location":"modules/#fd-parser","text":"FD-Parser is written in python. It\\'s located in external/fd and connected to the toolkit in planners/python/agnostic/py_strips_prob.hxx planners/python/agnostic/py_strips_prob.cxx creating a STRIPS Problem instance. Action costs can be ignored by setting in your python script task.ignore_action_costs = True as it\\'s done for example in /planners/bfs_f/bfs_f_unit_cost.py","title":"FD-parser"},{"location":"modules/#problem-representation-strips-model","text":"","title":"Problem Representation (STRIPS Model)"},{"location":"modules/#strips-problem-and-useful-information-like-mutexes-if-computed","text":"interfaces/agnostic/strips_prob.cxx interfaces/agnostic/strips_prob.hxx","title":"STRIPS Problem and useful information like mutexes (if computed)"},{"location":"modules/#strips-states","text":"interfaces/agnostic/strips_state.cxx interfaces/agnostic/strips_state.hxx","title":"STRIPS States"},{"location":"modules/#actions-and-fluents","text":"interfaces / agnostic / fluent . cxx interfaces / agnostic / fluent . hxx interfaces / agnostic / action . cxx interfaces / agnostic / action . hxx interfaces / agnostic / cond_eff . cxx interfaces / agnostic / cond_eff . hxx","title":"Actions and Fluents"},{"location":"modules/#successor-generator","text":"interfaces/agnostic/succ_gen.cxx interfaces/agnostic/succ_gen.hxx","title":"Successor Generator"},{"location":"modules/#running-experiments","text":"Scripts for running experiments, profiling, benchmarking and creating tables with Coverage, IPC Time and Quality Score are available benchmarks / run . py # Dependencies / Prerequisites : # - valgrind # - timeout # - dot ( graphviz ) # - krtoolkit Usage : python run . py profile < executable > < ipc directory > [ < domain pddl > < problem pddl > ] python run . py benchmark < executable > < ipc directory > < results directory > [ < domain > ] python run . py compare < directories with , separated > < ipc directory > python run . py clean Some Benchmark domains can be found at benchmarks/ipc-2006/ benchmarks/ipc-2011/ benchmarks/ipc-2014/ To use run.py script over new sets of benchmarks instead of specific domains, edit benchmarks/domains.py","title":"Running Experiments"},{"location":"modules/#examples","text":"","title":"Examples"},{"location":"modules/#ff-interface-example","text":"The example for the 'ff parser' interface can be found on * examples/ff-interface","title":"FF-Interface Example"},{"location":"modules/#fd-interface-example","text":"The example for the 'fD parser' interface can be found on * examples/fd-interface This is a very simple example that shows the basics for interfacing lwaptk with Fast Downward parser. In order to build the example issue the command: $ ./build.py and to run the example: $ ./parser.py <path to pddl domain file> <path to pddl problem file> if everything is working as it should, you should see FD parsing output on the standard output, as well as a dump of the grounded actions. Note that this will copy the folder externals/fd to the local directory, so DO NOT add it to the repository. If you need to do customize Fast Downward parsing scripts, just edit build.py to avoid it clobbering your local copy.","title":"FD-Interface Example"},{"location":"modules/#agnostic-interface-examples","text":"The examples for the 'planner agnostic' interface can be found on examples/agnostic-examples and cover the following topics:","title":"Agnostic Interface Examples"},{"location":"modules/#assembling-strips-problem-programatically","text":"Shows how to define a STRIPS planning problem programatically. * agnostic-examples/assembling_strips_problems","title":"Assembling STRIPS problem programatically"},{"location":"modules/#successor-generators","text":"Discusses and compares different ways of generating successors during search. * agnostic-examples/successor_generation","title":"Successor Generators"},{"location":"modules/#open-lists","text":"Discusses and compares different ways of creating open lists for your search algortithm. * agnostic-examples/fibonacci_open","title":"Open Lists"},{"location":"modules/#bfs-engine-variations","text":"Shows how can one assemble available components to deliver a planner built around a BFS search engine, with multiple queues and secondary heuristics, on a parametrized planning task. * agnostic-examples/bfs * agnostic-examples/bfs-double-queue * agnostic-examples/bfs-double-queue-secondary-heuristic","title":"BFS engine variations"},{"location":"modules/#bfs-h_max-greedydelayedanytime-ff-parser","text":"Shows how to assemble a classic planner: best-first search using h_max with multiple modes: greedy/delayed/anytime, over a task specified in PDDL and parsed by FF-parser * agnostic-examples/bfs-hmax","title":"BFS + h_max (greedy|delayed|anytime) + FF-parser"},{"location":"modules/#wa-variations-landmarks","text":"Shows how can one assemble available components to deliver a planner built around a WA* search engine, with multiple queues and secondary heuristics, on a parametrized planning task. Illustrates as well how to use landmark count heurstic. * agnostic-examples/wa-planner * agnostic-examples/rwa-planner","title":"WA* variations + landmarks"},{"location":"modules/#deadline-aware-search-engine","text":"Shows how can one assemble available components to deliver a planner built around Deadline Aware Search. * agnostic-examples/das","title":"Deadline Aware Search engine"},{"location":"modules/#breadth-first-search-ff-parser","text":"Shows how can one assemble available components to deliver a blind search planner. * agnostic-examples/brfs","title":"Breadth-First search + FF-parser"},{"location":"modules/#h_c-compilations-ff-parser","text":"Shows how can one use the \\Pi_C compilation to compute the h_C heuristic. Keyder et al. ICAPS 2012 * agnostic-examples/h_C_heuristics","title":"h_C compilations + FF-parser"},{"location":"modules/#replanner-changing-init-and-goal-situation-on-the-fly","text":"Shows how to create a replanner. It illustrates how to change the initial and goal states without having to parse the problem again, solving it with bfs+h_max. In the example we change the initial and goal situations by applying the first action of the current plan to progress the initial state, and last action of the plan to regress the goal. * agnostic-examples/replanner","title":"Replanner (changing init and goal situation on the fly)"},{"location":"modules/#width-based-algorithm-fd-parser","text":"Shows how SIW is implemented, using novelty function and FD parser * planners/siw","title":"Width-Based algorithm + FD parser"},{"location":"projects/","text":"Projects Link Here are some cool projects that are using LAPKT for different purposes. Classical Planners playing Atari 2600 games Link The Atari 2600 games supported in the Arcade Learning Environment (Bellemare et al., 2013) all feature a known initial (RAM) state and actions that have deterministic effects. Classical planners, however, cannot be used off-the-shelf as there is no compact PDDL-model of the games, and action effects and goals are not known a priori. Indeed, there are no explicit goals, and the planner must select actions on-line while interacting with a simulator that returns successor states and rewards. None of this precludes the use of blind lookahead algorithms for action selection like breadth-first search or Dijkstra's yet such methods are not effective over large state spaces. We thus turn to a different class of planning methods introduced recently that have been shown to be effective for solving large planning problems but which do not require prior knowledge of state transitions, costs (rewards) or goals. The empirical results over 54 Atari games show that the simplest such algorithm performs at the level of UCT, the state-of-the-art planning method in this domain, and suggest the potential of width-based methods for planning with simulators when factored, compact action models are not available. Find out more about it! Melissa: Planning for crop fields mapping with autonomous UAVs Link For managing production at the scale of crop fields, maps of plant pests are used to support farmer decisions. Such maps are costly to obtain since they require intensive surveys in the field, most of the time performed by human annotators or with human-controlled Unmanned Aerial Vehicles (UAVs). Melissa (the nymph that gave the honey to humankind), is a project where we look at the next challenge from an AI planning point of view: flying fully autonomous UAVs equipped with online sequential decision-making capabilities for pests sampling and mapping in crop fields. The system, embarked on the UAV, continuously updates a probabilistic representation of the crop field data from the sensing inputs, and selects a list of N sampling plots, to eventually obtain the best reconstructed map. These plots are then ordered, considering the side effects deriving from the spatial model of the observed data, and a trajectory planned by the classical planning engine (Lapkt). The plan is then applied until the number of actual observations that differ from expected ones exceeds a given threshold, which triggers a new replanning episode. This planning method favourably compares on the problem of weed map construction against existing greedy approaches while adding the advantage of being adapted to autonomous UAVs' flying time constraints. This project is a joint work between ONERA and INRA. Contact: Alexandre Albore. TRAPPER: Invariants, Traps, and Dead-end detection Link We consider the problem of deriving formulas that capture traps, invariants, and dead-ends in classical planning through polynomial forms of preprocessing. An invariant is a formula that is true in the initial state and in all reachable states. A trap is a conditional invariant: once a state is reached that makes the trap true, all the states that are reachable from it will satisfy the trap formula as well. Finally, dead-ends are formulas that are satisfied in states that make the goal unreachable. We introduce a preprocessing algorithm that computes traps in k-DNF form that is exponential in the k parameter, and show how the algorithm can be used to precompute invariants and dead-ends. We report also preliminary tests that illustrate the effectiveness of the preprocessing algorithm for identifying dead-end states, and compare it with the identification that follows from the use of the h\\^1 and h\\^2 heuristics that cannot be preprocessed, and must be computed at run time. Source Code ICAPS 2016 paper BFWS: Best First Width Search Planners Link It has been shown recently that goal-oriented search (heuristic exploitation) and width-based search (structural exploration) can be combined to produce planning algorithms with a performance that goes beyond the state-of-the-art. Such algorithms are based on best-first width search (BFWS), a plain best-first search set with evaluations functions combined lexicographically to break ties, some of which express novelty based preferences. In BFWS(f5), for example, the evaluation function f5 weights nodes by a novelty measure, breaking ties by the number of non-achieved goals. BFWS(f5) is a best-first algorithm, and hence, it is complete but not polynomial, and its performance doesn't match the state of the art. In this work we show, however, that incomplete versions of BFWS(f5) where nodes with novelty greater than k are pruned, are not only polynomial but have an empirical performance that is better than both BFWS(f5) and state-of-the-art planners. This is shown by considering all the international planning competition instances. This is the first time where polynomial algorithms with meaningful bounds are shown to achieve state-of-the-art performance in planning. Practical and theoretical implications of this empirical finding are briefly sketched. Source Code AAAI 2017 - BFWS framework paper ICAPS 2017 - polynomial BFWS versions paper","title":"Projects"},{"location":"projects/#projects","text":"Here are some cool projects that are using LAPKT for different purposes.","title":"Projects"},{"location":"projects/#classical-planners-playing-atari-2600-games","text":"The Atari 2600 games supported in the Arcade Learning Environment (Bellemare et al., 2013) all feature a known initial (RAM) state and actions that have deterministic effects. Classical planners, however, cannot be used off-the-shelf as there is no compact PDDL-model of the games, and action effects and goals are not known a priori. Indeed, there are no explicit goals, and the planner must select actions on-line while interacting with a simulator that returns successor states and rewards. None of this precludes the use of blind lookahead algorithms for action selection like breadth-first search or Dijkstra's yet such methods are not effective over large state spaces. We thus turn to a different class of planning methods introduced recently that have been shown to be effective for solving large planning problems but which do not require prior knowledge of state transitions, costs (rewards) or goals. The empirical results over 54 Atari games show that the simplest such algorithm performs at the level of UCT, the state-of-the-art planning method in this domain, and suggest the potential of width-based methods for planning with simulators when factored, compact action models are not available. Find out more about it!","title":"Classical Planners playing Atari 2600 games"},{"location":"projects/#melissa-planning-for-crop-fields-mapping-with-autonomous-uavs","text":"For managing production at the scale of crop fields, maps of plant pests are used to support farmer decisions. Such maps are costly to obtain since they require intensive surveys in the field, most of the time performed by human annotators or with human-controlled Unmanned Aerial Vehicles (UAVs). Melissa (the nymph that gave the honey to humankind), is a project where we look at the next challenge from an AI planning point of view: flying fully autonomous UAVs equipped with online sequential decision-making capabilities for pests sampling and mapping in crop fields. The system, embarked on the UAV, continuously updates a probabilistic representation of the crop field data from the sensing inputs, and selects a list of N sampling plots, to eventually obtain the best reconstructed map. These plots are then ordered, considering the side effects deriving from the spatial model of the observed data, and a trajectory planned by the classical planning engine (Lapkt). The plan is then applied until the number of actual observations that differ from expected ones exceeds a given threshold, which triggers a new replanning episode. This planning method favourably compares on the problem of weed map construction against existing greedy approaches while adding the advantage of being adapted to autonomous UAVs' flying time constraints. This project is a joint work between ONERA and INRA. Contact: Alexandre Albore.","title":"Melissa: Planning for crop fields mapping with autonomous UAVs"},{"location":"projects/#trapper-invariants-traps-and-dead-end-detection","text":"We consider the problem of deriving formulas that capture traps, invariants, and dead-ends in classical planning through polynomial forms of preprocessing. An invariant is a formula that is true in the initial state and in all reachable states. A trap is a conditional invariant: once a state is reached that makes the trap true, all the states that are reachable from it will satisfy the trap formula as well. Finally, dead-ends are formulas that are satisfied in states that make the goal unreachable. We introduce a preprocessing algorithm that computes traps in k-DNF form that is exponential in the k parameter, and show how the algorithm can be used to precompute invariants and dead-ends. We report also preliminary tests that illustrate the effectiveness of the preprocessing algorithm for identifying dead-end states, and compare it with the identification that follows from the use of the h\\^1 and h\\^2 heuristics that cannot be preprocessed, and must be computed at run time. Source Code ICAPS 2016 paper","title":"TRAPPER: Invariants, Traps, and Dead-end detection"},{"location":"projects/#bfws-best-first-width-search-planners","text":"It has been shown recently that goal-oriented search (heuristic exploitation) and width-based search (structural exploration) can be combined to produce planning algorithms with a performance that goes beyond the state-of-the-art. Such algorithms are based on best-first width search (BFWS), a plain best-first search set with evaluations functions combined lexicographically to break ties, some of which express novelty based preferences. In BFWS(f5), for example, the evaluation function f5 weights nodes by a novelty measure, breaking ties by the number of non-achieved goals. BFWS(f5) is a best-first algorithm, and hence, it is complete but not polynomial, and its performance doesn't match the state of the art. In this work we show, however, that incomplete versions of BFWS(f5) where nodes with novelty greater than k are pruned, are not only polynomial but have an empirical performance that is better than both BFWS(f5) and state-of-the-art planners. This is shown by considering all the international planning competition instances. This is the first time where polynomial algorithms with meaningful bounds are shown to achieve state-of-the-art performance in planning. Practical and theoretical implications of this empirical finding are briefly sketched. Source Code AAAI 2017 - BFWS framework paper ICAPS 2017 - polynomial BFWS versions paper","title":"BFWS: Best First Width Search Planners"}]}